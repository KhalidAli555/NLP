{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bPM_VbOaG-a9"
      },
      "outputs": [],
      "source": [
        "x=\"Natural language processing (NLP) is a branch of artificial intelligence (AI) that enables computers to comprehend, generate, and manipulate human language. Natural language processing has the ability to interrogate the data with natural language text or voice.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVSTU5D8KIak"
      },
      "source": [
        "# **Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KJTMNLsmJ4nw"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize,sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUbBS69-Kc88",
        "outputId": "929b379b-7d65-44f2-e2c0-39668eab744c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsMt4tPmKFHg",
        "outputId": "2615d980-437b-4eb9-9644-e0762fd0a9b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural language processing (NLP) is a branch of artificial intelligence (AI) that enables computers to comprehend, generate, and manipulate human language.',\n",
              " 'Natural language processing has the ability to interrogate the data with natural language text or voice.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# sentence tokenization\n",
        "sent=sent_tokenize(x)  # it seperate sentencea after full stop\n",
        "sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEUCTmbyKXOR",
        "outputId": "68f09c0a-c44e-442e-b11d-9af71f601beb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " '(',\n",
              " 'NLP',\n",
              " ')',\n",
              " 'is',\n",
              " 'a',\n",
              " 'branch',\n",
              " 'of',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " '(',\n",
              " 'AI',\n",
              " ')',\n",
              " 'that',\n",
              " 'enables',\n",
              " 'computers',\n",
              " 'to',\n",
              " 'comprehend',\n",
              " ',',\n",
              " 'generate',\n",
              " ',',\n",
              " 'and',\n",
              " 'manipulate',\n",
              " 'human',\n",
              " 'language',\n",
              " '.',\n",
              " 'Natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'has',\n",
              " 'the',\n",
              " 'ability',\n",
              " 'to',\n",
              " 'interrogate',\n",
              " 'the',\n",
              " 'data',\n",
              " 'with',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'text',\n",
              " 'or',\n",
              " 'voice',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#work tokenization\n",
        "word=word_tokenize(x) # it seperate the sentence word by word\n",
        "word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Paf1795cLKiK"
      },
      "source": [
        "# ***Stop Word Removal***\n",
        "these are actually the most common words in any language and does not add nuch information to the text.\n",
        "e.g: the ,a an, so ,that, or ,and etc  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TQByg49iK9c3"
      },
      "outputs": [],
      "source": [
        "x=\"Natural language processing (NLP) is a branch of artificial intelligence (AI) that enables computers to comprehend, generate, and manipulate human language. Natural language processing has the ability to interrogate the data with natural language text or voice.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1gHa8tVpLEw-"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbaSdAjQNAHq",
        "outputId": "0596dff7-a4a7-4b4f-cad2-72fff2c59a05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw6rV3hGMa-K",
        "outputId": "a4b438ce-7c39-4531-9386-ac722eb43136"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "stop_word=stopwords.words('english') # english means ap ny kn se language use krni ha\n",
        "stop_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5ydNn8zNNEd4"
      },
      "outputs": [],
      "source": [
        "new_x=word_tokenize(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mXEt0DnKNkup",
        "outputId": "69419892-581b-4904-d5e3-b5f39c6ca395"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "punctuation # all punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "J72K5nhHNY8v"
      },
      "outputs": [],
      "source": [
        "stop_word_list=list(punctuation)+stop_word #  print punctuation and stop word in english"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwIQrXbeNtME",
        "outputId": "9ccc0614-ef13-4ae4-90c7-d24df7c68b2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " '`',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~',\n",
              " 'i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "stop_word_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9eOiCwgNuqF",
        "outputId": "077f5827-62f7-4a5a-9b0f-0058c4fe76ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural\n",
            "language\n",
            "processing\n",
            "NLP\n",
            "branch\n",
            "artificial\n",
            "intelligence\n",
            "AI\n",
            "enables\n",
            "computers\n",
            "comprehend\n",
            "generate\n",
            "manipulate\n",
            "human\n",
            "language\n",
            "Natural\n",
            "language\n",
            "processing\n",
            "ability\n",
            "interrogate\n",
            "data\n",
            "natural\n",
            "language\n",
            "text\n",
            "voice\n"
          ]
        }
      ],
      "source": [
        "# it remove all stopword and punctuation form our input\n",
        "for i in new_x:\n",
        "  if i not in stop_word_list:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK-0ILmFOl7T"
      },
      "source": [
        "# ***Stemming & Lemmatization***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lk4lG3ecOtFt"
      },
      "source": [
        "# **Stemming**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y71s_jtvOwty"
      },
      "source": [
        "it is a technique used to extract the base from the words by removing affixes form them.\n",
        "\n",
        "e.g: changing........chang\n",
        "\n",
        "     changing........chang\n",
        "\n",
        "     changing........chang\n",
        "     &\n",
        "     studying....studi\n",
        "\n",
        "     studies....studi\n",
        "\n",
        "     study....studi\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nz_D6V7fODqN"
      },
      "outputs": [],
      "source": [
        "x=\"Natural language processing (NLP) is a branch of artificial intelligence (AI) that enables computers to comprehend, generate, and manipulate human language. Natural language processing has the ability to interrogate the data with natural language text or voice.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UPdfUd5lPqjE"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import LancasterStemmer,RegexpStemmer,PorterStemmer,SnowballStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pcgz7DwvP1Oo"
      },
      "outputs": [],
      "source": [
        "l=LancasterStemmer()\n",
        "r=RegexpStemmer('ing')  # it take default parameter\n",
        "p=PorterStemmer()\n",
        "s=SnowballStemmer(\"english\") # works on 15 different languages.it choose english"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnMJV9qFQHew",
        "outputId": "448124d7-08ad-43bc-9752-e9c3a461a7c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chang\n",
            "chang\n",
            "chang\n",
            "chang\n"
          ]
        }
      ],
      "source": [
        "print(l.stem(\"changing\"))\n",
        "print(r.stem(\"changing\"))\n",
        "print(p.stem(\"changing\"))\n",
        "print(s.stem(\"changing\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRCZMEa_Qy_m"
      },
      "source": [
        "# **Lemmatization**\n",
        "it is same like stemming.\n",
        "the output get after lemmatization is lemma.\n",
        "After lemmatization we will be getting a valid word that means same thing\n",
        "(mtlb ye word ko cutt kry ga or sath m sementic(meaningful) word b dy ga).\n",
        "\n",
        "e.g:  \n",
        "\n",
        "     studying...study\n",
        "\n",
        "     studies....study\n",
        "\n",
        "     study......study\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xwpNFfpmQo6y"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K7li61pSRKd",
        "outputId": "2e7f7ca4-9279-42a0-b3ac-296f0ddc9fbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-rz5nB1R4hv",
        "outputId": "7e2e7b9a-d5d0-40cf-b844-438d45065cd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<WordNetLemmatizer>\n"
          ]
        }
      ],
      "source": [
        "wl=WordNetLemmatizer()\n",
        "\n",
        "wl.lemmatize(\"studying\")\n",
        "print(wl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGyOsmTeSqbI",
        "outputId": "f81eb637-1ec1-4f87-ca12-d984d0712f3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running -> running\n",
            "swimming -> swimming\n",
            "better -> better\n",
            "cats -> cat\n",
            "children -> child\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Initialize the lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Example words\n",
        "words = ['running', 'swimming', 'better', 'cats', 'children']\n",
        "\n",
        "# Lemmatize each word\n",
        "for word in words:\n",
        "    print(f\"{word} -> {lemmatizer.lemmatize(word)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***N-Gram***\n",
        "it can be defined as the neighboring sequenes of items in a document.\n",
        "(mtlb ye ky agr hm 1 word lkhty hn to us ky bad agla word kia ay ga us ky bad agla word kia ay gan ye cheese suggest krta ha.)\n",
        "\n",
        "**BigramCollocationFinder**: Finds bigrams (pairs of consecutive words).\n",
        "\n",
        "**TrigramCollocationFinder**: Finds trigrams (three consecutive words).\n",
        "\n",
        "**ngrams**: Generates n-grams (sequences of n consecutive words)."
      ],
      "metadata": {
        "id": "lXCbqCwc_rSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=\"Natural language processing (NLP) is a branch of artificial intelligence (AI) that enables computers to comprehend, generate, and manipulate human language. Natural language processing has the ability to interrogate the data with natural language text or voice.\""
      ],
      "metadata": {
        "id": "TiW_O8Xf_sA7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "1jNxBUY2_wsG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w=word_tokenize(x)\n",
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W27SM1Ml_zGO",
        "outputId": "f7743664-586a-4784-d985-5a46d808ff67"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " '(',\n",
              " 'NLP',\n",
              " ')',\n",
              " 'is',\n",
              " 'a',\n",
              " 'branch',\n",
              " 'of',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " '(',\n",
              " 'AI',\n",
              " ')',\n",
              " 'that',\n",
              " 'enables',\n",
              " 'computers',\n",
              " 'to',\n",
              " 'comprehend',\n",
              " ',',\n",
              " 'generate',\n",
              " ',',\n",
              " 'and',\n",
              " 'manipulate',\n",
              " 'human',\n",
              " 'language',\n",
              " '.',\n",
              " 'Natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'has',\n",
              " 'the',\n",
              " 'ability',\n",
              " 'to',\n",
              " 'interrogate',\n",
              " 'the',\n",
              " 'data',\n",
              " 'with',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'text',\n",
              " 'or',\n",
              " 'voice',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
        "from nltk.util import ngrams"
      ],
      "metadata": {
        "id": "mv7SI4Kl_1Tr"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b=BigramCollocationFinder.from_words(w)\n",
        "t=TrigramCollocationFinder.from_words(w)\n",
        "n=ngrams(w,1)  # w means input and 1 means  1 time ktny word repeat hvy hain"
      ],
      "metadata": {
        "id": "nTQarQh3_51y"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.ngram_fd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6VjKuYq_8TB",
        "outputId": "30aa9bc1-b82d-4afc-97f9-4d4e8a196567"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({('Natural', 'language'): 2, ('language', 'processing'): 2, ('processing', '('): 1, ('(', 'NLP'): 1, ('NLP', ')'): 1, (')', 'is'): 1, ('is', 'a'): 1, ('a', 'branch'): 1, ('branch', 'of'): 1, ('of', 'artificial'): 1, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.ngram_fd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRtJipM1AAEk",
        "outputId": "b8fb33d7-c50c-4bd8-ad59-6fe349007bd3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({('Natural', 'language', 'processing'): 2, ('language', 'processing', '('): 1, ('processing', '(', 'NLP'): 1, ('(', 'NLP', ')'): 1, ('NLP', ')', 'is'): 1, (')', 'is', 'a'): 1, ('is', 'a', 'branch'): 1, ('a', 'branch', 'of'): 1, ('branch', 'of', 'artificial'): 1, ('of', 'artificial', 'intelligence'): 1, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in n:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV-vAMJ2ADC8",
        "outputId": "1754dfea-c262-4fc2-8a11-aadef8fa7de1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Natural',)\n",
            "('language',)\n",
            "('processing',)\n",
            "('(',)\n",
            "('NLP',)\n",
            "(')',)\n",
            "('is',)\n",
            "('a',)\n",
            "('branch',)\n",
            "('of',)\n",
            "('artificial',)\n",
            "('intelligence',)\n",
            "('(',)\n",
            "('AI',)\n",
            "(')',)\n",
            "('that',)\n",
            "('enables',)\n",
            "('computers',)\n",
            "('to',)\n",
            "('comprehend',)\n",
            "(',',)\n",
            "('generate',)\n",
            "(',',)\n",
            "('and',)\n",
            "('manipulate',)\n",
            "('human',)\n",
            "('language',)\n",
            "('.',)\n",
            "('Natural',)\n",
            "('language',)\n",
            "('processing',)\n",
            "('has',)\n",
            "('the',)\n",
            "('ability',)\n",
            "('to',)\n",
            "('interrogate',)\n",
            "('the',)\n",
            "('data',)\n",
            "('with',)\n",
            "('natural',)\n",
            "('language',)\n",
            "('text',)\n",
            "('or',)\n",
            "('voice',)\n",
            "('.',)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Count Vectorizer**\n",
        "It convert textual data into numerical data that machine learning models can work with."
      ],
      "metadata": {
        "id": "dtTDf8udALmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Sample text data\n",
        "text = [\n",
        "    'I love programming in Python',\n",
        "    'Python is great for data science',\n",
        "    'I love data science and Python programming'\n",
        "]\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the text data into a matrix of token counts\n",
        "X = vectorizer.fit_transform(text)\n",
        "\n",
        "# View the matrix of token counts\n",
        "print(X.toarray())\n",
        "\n",
        "# Get the feature names (i.e., the vocabulary)\n",
        "print(vectorizer.get_feature_names_out())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiZF6V_cAF-F",
        "outputId": "a42ad14b-dc89-43bc-db87-fe2cbe8d7c12"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0 1 0 1 1 1 0]\n",
            " [0 1 1 1 0 1 0 0 1 1]\n",
            " [1 1 0 0 0 0 1 1 1 1]]\n",
            "['and' 'data' 'for' 'great' 'in' 'is' 'love' 'programming' 'python'\n",
            " 'science']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}